{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa è l'ultima versione del codice per la classificazione di MNIST con uno Stochastic Quantum Walker.\n",
    "L'unico pacchetto \"non-standard\" è torchdiffeq, la cui funzione odeint_adjoint risolve equazioni differenziali utilizzando O(1) di memoria per la backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torchdiffeq import odeint_adjoint as odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dataset sono caricati nei dataloader. MNIST è già encodato a 64 feature e paddato con gli ultimi 10 pixel pari a 0. Da notare che le immagini sono già in formato torch.complex64. Inoltre, nel notebook dell'autoencoder, l'encoder ha come ultimo layer una ReLU e non una sigmoide! Questo significa che i pixel non hanno più valori compresi tra 0 e 1. La ragione di questa scelta è perché nel caso della sigmoide, e al contrario della ReLU, il training non riusciva (non so bene perché) a ottimizzare a sufficienza e la loss rimaneva alta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni dataset: torch.Size([128, 74]), torch.Size([128])\n",
      "Data type: torch.complex64, torch.int64\n",
      "Padding: tensor([0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j])\n"
     ]
    }
   ],
   "source": [
    "class StochasticMNIST(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "# Carico le immagini encodate\n",
    "train_data, train_targets = torch.load(\"qsw_train_data_encoded64.pt\", weights_only=False)\n",
    "test_data, test_targets = torch.load(\"qsw_test_data_encoded64.pt\", weights_only=False)\n",
    "\n",
    "# Creo i dataset\n",
    "qsw_train_data = StochasticMNIST(train_data, train_targets)\n",
    "qsw_test_data = StochasticMNIST(test_data, test_targets)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "qsw_train_dataloader = DataLoader(qsw_train_data, batch_size=batch_size, shuffle=True, num_workers=32)\n",
    "qsw_test_dataloader = DataLoader(qsw_test_data, batch_size=batch_size, shuffle=True, num_workers=32)\n",
    "\n",
    "for X, y in qsw_train_dataloader:\n",
    "    print(f'Dimensioni dataset: {X.shape}, {y.shape}')\n",
    "    print(f'Data type: {X.dtype}, {y.dtype}')\n",
    "    print(f'Padding: {X[0,-10:]}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definisco la classe SQWalker del modello e la classe LindbladFunc. Quest'ultima è necessaria per implementare correttamente la funzione odeint_adjoint. In altre parole, dato il problema di Cauchy\n",
    "\n",
    "dy/dt = f(t, y)    y(t_0) = y_0.\n",
    "\n",
    "odeint_adjoint(func, y0, t) necessita che func sia un nn.Module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LindbladFunc(nn.Module):\n",
    "    def __init__(self, N, s, l, p, device):\n",
    "        self.factory_kwargs = {\"device\": device, \"dtype\": torch.complex64}\n",
    "        super().__init__()\n",
    "        # Inizializzo i parametri del modello.\n",
    "        self.n = math.isqrt(N)\n",
    "        self.N = N\n",
    "        self.s = s\n",
    "        self.p = p\n",
    "\n",
    "        # Costruisco la matrice di transizione e la popolo con i pesi da trainare.\n",
    "        # Per semplicità scelgo i primi 10 nodi come quelli collegati ai sink.\n",
    "        self.sinkrates = nn.parameter.Parameter(\n",
    "            torch.empty((1, self.s), requires_grad=True, **self.factory_kwargs)\n",
    "        )\n",
    "        self.mask_sinks = torch.zeros((self.s, self.N), **self.factory_kwargs)\n",
    "        self.mask_sinks.fill_diagonal_(1)\n",
    "\n",
    "        # Costruisco dei tensori ausiliari per l'integrazione.\n",
    "        self.B = torch.zeros(self.N + self.s, self.N + self.s, **self.factory_kwargs)\n",
    "        self.B[:self.N, :self.N] = 0.5 * self.p * torch.eye(self.N, **self.factory_kwargs)\n",
    "\n",
    "        # Costruisco la matrice del lattice e la popolo con i pesi da trainare.\n",
    "        self.mask = self._create_mask(l, device)\n",
    "        self.expressivity = torch.count_nonzero(self.mask)\n",
    "        self.weights = nn.parameter.Parameter(\n",
    "            torch.empty((1, self.expressivity), requires_grad=True, **self.factory_kwargs)\n",
    "        )\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def _create_mask(self, l, device):\n",
    "        '''Restituisce una maschera per le entrate non nulle di una matrice di adiacenza di un lattice.\n",
    "        Non saprei dire quanto sia efficiente, ma è il modo più carino che mi è venuto in mente.\n",
    "        \n",
    "        Parametri\n",
    "        ---------\n",
    "        l : int tra 1 e n-1, dove n è la dimensione dell'immagine (es. per MNIST non encodato n=28)\n",
    "\n",
    "        Ritorna\n",
    "        -------\n",
    "        torch.tensor con dtype = torch.bool\n",
    "        '''\n",
    "        # Il tensore moves determina la struttura della cella a l-vicini.\n",
    "        moves = torch.ones(2*l+1, 2*l+1, device=device)\n",
    "        moves[l,l] = 0\n",
    "\n",
    "        M = nn.functional.pad(moves, (self.n-l-1, self.n-l-1, self.n-l-1, self.n-l-1), 'constant', 0)\n",
    "\n",
    "        m = torch.zeros((self.N, self.N), device=device)\n",
    "        for i in range(self.n):\n",
    "            for j in range(self.n):\n",
    "                m[i*self.n+j] = M[self.n-1-i:2*self.n-1-i, self.n-1-j:2*self.n-1-j].flatten()\n",
    "        return m == 1\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        # Impostare a=sqrt(5) in kaiming_uniform equivale a inizializzare con\n",
    "        # uniform(-1/sqrt(n_features), 1/sqrt(n_features)).\n",
    "        nn.init.kaiming_uniform_(self.weights, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.sinkrates, a=math.sqrt(5))\n",
    "\n",
    "    def update_walker(self):\n",
    "        '''Aggiorna i tensori nell'eq. di Lindblad'''\n",
    "        \n",
    "        # Definisco le matrici A e gamma.\n",
    "        self.A = torch.zeros((self.N, self.N), **self.factory_kwargs)\n",
    "        self.A[self.mask] = self.weights\n",
    "        self.A = self.A - 1j * self.A.imag\n",
    "        self.A = 0.5*(self.A + self.A.T)**2\n",
    "\n",
    "        self.gamma = torch.zeros((self.s, self.N), **self.factory_kwargs)\n",
    "        self.gamma[self.mask_sinks == 1] = self.sinkrates\n",
    "        self.gamma = self.gamma - 1j * self.gamma.imag\n",
    "        self.gamma = (self.gamma)**2\n",
    "\n",
    "        # Calcolo le connettività della matrice A.\n",
    "        degA = torch.sum(self.A, dim=0) \n",
    "            \n",
    "        # Aggiorno la laplaciana.\n",
    "        self.laplacian = torch.zeros(self.N + self.s, self.N + self.s, **self.factory_kwargs)\n",
    "        self.laplacian[:self.N, :self.N] = self.p * self.A / degA\n",
    "        self.laplacian[self.N:, :self.N]= self.gamma\n",
    "\n",
    "        # Calcolo la matrice a del foglio LaTeX.\n",
    "        R = torch.zeros(self.N + self.s, self.N + self.s, **self.factory_kwargs)\n",
    "        R[self.N:, :self.N] = self.gamma\n",
    "        self.a = 0.5 * torch.diag(torch.sum(R, dim=0)) + self.B\n",
    "\n",
    "        # Aggiorno l'hamiltoniana.\n",
    "        self.H = torch.eye(self.N + self.s, **self.factory_kwargs)\n",
    "        self.H[:self.N, :self.N] = (1 - self.p) * self.A\n",
    "    \n",
    "    def forward(self, t, rho):\n",
    "        '''Metodo che viene chiamato da odeint durante l'integrazione.\n",
    "        Calcola l'rhs dell'eq. di Lindblad\n",
    "        '''\n",
    "        drho = -1j * (torch.matmul(self.H, rho) - torch.matmul(rho, self.H))\n",
    "        drho = drho + torch.diag_embed(torch.matmul(torch.diagonal(rho, dim1 = 1, dim2 = 2), self.laplacian.T))\n",
    "        drho = drho - (torch.matmul(self.a, rho) + torch.matmul(rho, self.a))\n",
    "        return drho\n",
    "    \n",
    "    def extra_repr(self) -> str:\n",
    "        return \"in_features: {a}, out_features: {b}\\n Expressivity: {c:.2f}%\".format(a = self.N, b = self.s, c = self.expressivity*100/self.N**2)\n",
    "\n",
    "class SQWalker(nn.Module):\n",
    "    '''Classe dello Stochastic Quantum Walker'''\n",
    "    def __init__(self, in_features, out_features, dt=1e-3, steps=1000, l = 1, noise=1., device = None):\n",
    "        super().__init__()\n",
    "        self.s = out_features\n",
    "        self.lindblad = LindbladFunc(in_features, out_features, l, noise, device)\n",
    "        self.t = torch.arange(steps+1, device=device)*dt\n",
    "        \n",
    "    def forward(self, input, history = False, method = 'rk4'):\n",
    "        '''\n",
    "        Parametri\n",
    "        ---------\n",
    "        \n",
    "        Ritorna\n",
    "        -------\n",
    "        se history=False\n",
    "            output.real: torch.tensor di shape (batch_size, s) che contiene il valore dei sink nello stato finale\n",
    "        se history = True\n",
    "            result: torch.tensor di shape (batch, steps, n, n) che contiene il valore di rho a tutti gli istanti.\n",
    "            '''\n",
    "        self.lindblad.update_walker()\n",
    "\n",
    "        # Costruisco la matrice densità iniziale popolando la diagonale con l'immagine.\n",
    "        rho0 = torch.diag_embed(input)\n",
    "        \n",
    "        # Integro con Runge-Kutta al quart'ordine. Se method non fosse specificato,\n",
    "        # odeint userebbe il metodo Dormand-Price (Runge-Kutta adattivo di ordine 5).\n",
    "        result = odeint(self.lindblad, y0=rho0, t=self.t, method = method)\n",
    "\n",
    "        if history == True:\n",
    "            return result\n",
    "        output = result[-1].diagonal(dim1=-2, dim2=-1)[:, -self.s:]\n",
    "        \n",
    "        return output.real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definisco il modello, indicando la dimensione di input e di output, i parametri dell'integrazione, il passo del lattice e il noise. La scelta di mettere dt=1. sembra pareccchio azzardata. Vedremo a posteriori che l'integrazione lavora comunque a modo. Il vantaggio è ovvio: se la cosa è lecita, bastano pochissimi passi e il training viene eseguito in un tempo ragionevole. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQWalker(\n",
      "  (lindblad): LindbladFunc(\n",
      "    in_features: 64, out_features: 10\n",
      "     Expressivity: 26.66%\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SQWalker(64, 10, dt = 1., steps = 50, l = 2, noise = 0.2, device = device).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, voice = True):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    current = 0\n",
    "    i = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        current += len(X)\n",
    "\n",
    "        if current >= i*10000 and voice:\n",
    "            i += 1\n",
    "            loss = loss.item()\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return 100*correct, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 6.976196  [  128/60000]\n",
      "loss: 2.359960  [10112/60000]\n",
      "loss: 2.358345  [20096/60000]\n",
      "loss: 2.366081  [30080/60000]\n",
      "loss: 2.315771  [40064/60000]\n",
      "loss: 2.269418  [50048/60000]\n",
      "loss: 2.164721  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 17.4%, Avg loss: 2.196330 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.200248  [  128/60000]\n",
      "loss: 2.095577  [10112/60000]\n",
      "loss: 1.962765  [20096/60000]\n",
      "loss: 1.870384  [30080/60000]\n",
      "loss: 1.814348  [40064/60000]\n",
      "loss: 1.852032  [50048/60000]\n",
      "loss: 1.750075  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 38.0%, Avg loss: 1.786620 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.753733  [  128/60000]\n",
      "loss: 1.755722  [10112/60000]\n",
      "loss: 1.632880  [20096/60000]\n",
      "loss: 1.677761  [30080/60000]\n",
      "loss: 1.664694  [40064/60000]\n",
      "loss: 1.707820  [50048/60000]\n",
      "loss: 1.685152  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 41.6%, Avg loss: 1.659997 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.834330  [  128/60000]\n",
      "loss: 1.667251  [10112/60000]\n",
      "loss: 1.618830  [20096/60000]\n",
      "loss: 1.718327  [30080/60000]\n",
      "loss: 1.599446  [40064/60000]\n",
      "loss: 1.509332  [50048/60000]\n",
      "loss: 1.579569  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 43.6%, Avg loss: 1.627104 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.678139  [  128/60000]\n",
      "loss: 1.754547  [10112/60000]\n",
      "loss: 1.544621  [20096/60000]\n",
      "loss: 1.676558  [30080/60000]\n",
      "loss: 1.652973  [40064/60000]\n",
      "loss: 1.568396  [50048/60000]\n",
      "loss: 1.650756  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 47.3%, Avg loss: 1.556685 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.555894  [  128/60000]\n",
      "loss: 1.699073  [10112/60000]\n",
      "loss: 1.643413  [20096/60000]\n",
      "loss: 1.548360  [30080/60000]\n",
      "loss: 1.625721  [40064/60000]\n",
      "loss: 1.502787  [50048/60000]\n",
      "loss: 1.517424  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.457950 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.466805  [  128/60000]\n",
      "loss: 1.510977  [10112/60000]\n",
      "loss: 1.368508  [20096/60000]\n",
      "loss: 1.635465  [30080/60000]\n",
      "loss: 1.335170  [40064/60000]\n",
      "loss: 1.410395  [50048/60000]\n",
      "loss: 1.421598  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Avg loss: 1.402308 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.272949  [  128/60000]\n",
      "loss: 1.478844  [10112/60000]\n",
      "loss: 1.397019  [20096/60000]\n",
      "loss: 1.327564  [30080/60000]\n",
      "loss: 1.351726  [40064/60000]\n",
      "loss: 1.310595  [50048/60000]\n",
      "loss: 1.317355  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 51.0%, Avg loss: 1.358636 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.445635  [  128/60000]\n",
      "loss: 1.221565  [10112/60000]\n",
      "loss: 1.259444  [20096/60000]\n",
      "loss: 1.337008  [30080/60000]\n",
      "loss: 1.297114  [40064/60000]\n",
      "loss: 1.395396  [50048/60000]\n",
      "loss: 1.193642  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Avg loss: 1.317256 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.319802  [  128/60000]\n",
      "loss: 1.287821  [10112/60000]\n",
      "loss: 1.373601  [20096/60000]\n",
      "loss: 1.412605  [30080/60000]\n",
      "loss: 1.339187  [40064/60000]\n",
      "loss: 1.331897  [50048/60000]\n",
      "loss: 1.217239  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 1.338693 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(qsw_train_dataloader, model, loss_fn, optimizer)\n",
    "    test(qsw_test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SQWalker(64, 10, dt = 1., steps = 100, l = 2, noise = 0.2, device = device).to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifichiamo adesso che l'integrazione non crei problemi. Per farlo, prendiamo una immagine a caso e effettuiamo l'integrazione sia col metodo rk4, sia chiamando il metodo dopri5 (Dormand-Price). Quest'ultimo è un metodo adattivo che sceglie autonomamente il passo d'integrazione: i valori di dt e steps rappresentano allora soltanto gli istanti per i quali odeint deve restituire il valore di rho, ma non cambiano la precisione dell'integrazione.\n",
    "Quando avevo fatto questa operazione per il caso full connected, mi ero reso conto che solo per dt molto piccoli le integrazioni combaciavano. In questo caso invece, per dt=1 lo stato finale è identico per i due metodi. C'era poi un altro problema che mi aveva portato a concludere che dt dovesse essere molto piccolo, ma era un errore di codice che poi vi spiegherò a voce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergenza: 77.68%\n",
      "Stato finale rk4: tensor([19.0231, 19.3966, 17.9123, 18.9633, 24.2981, 34.5946, 29.2684, 24.4562,\n",
      "        18.9291, 30.4236], device='cuda:0')\n",
      "Stato finale reale: tensor([19.0231, 19.3966, 17.9123, 18.9633, 24.2981, 34.5946, 29.2684, 24.4562,\n",
      "        18.9291, 30.4236], device='cuda:0')\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "classes = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "\n",
    "model.eval()\n",
    "n_datas = len(test_data)\n",
    "\n",
    "c = torch.randint(n_datas,(1,)).item()\n",
    "x, y = qsw_test_data[c]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x.unsqueeze(0), history=True).squeeze(1)\n",
    "    sinks = pred[-1].diagonal(dim1=-2, dim2=-1)[-10:].real\n",
    "    \n",
    "    pred_real = model(x.unsqueeze(0), history=True, method = 'dopri5').squeeze(1)\n",
    "    sinks_real = pred_real[-1].diagonal(dim1=-2, dim2=-1)[-10:].real\n",
    "\n",
    "    predicted, actual = classes[sinks.argmax()], classes[y]\n",
    "\n",
    "# Stampo la percentuale del valore totale dei pixel che è finito nei sink\n",
    "print(f'Convergenza: {(100*torch.sum(sinks)/torch.sum(x.real)):.2f}%')\n",
    "\n",
    "# Confronto i due stati finali nei sink\n",
    "print(f'Stato finale rk4: {sinks}\\nStato finale reale: {sinks_real}')\n",
    "\n",
    "# Confronto i due stati finali anche per le entrate off-diagonal. Probabilmente qua verrà False.\n",
    "# Tuttavia nella prossima cella ci accorgiamo comunque che le differenze sono minime\n",
    "print(torch.allclose(pred[-1], pred_real[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(torch.abs(pred[-1] - pred_real[-1]).cpu().numpy())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
